import json
import os
import sys
import time
import random
import re
from pathlib import Path
import requests
from t1 import search_and_fetch, human_sleep

def save_cover_image(cover_url, book_id, cover_dir="covers"):
    """
    ä¿å­˜å°é¢å›¾ç‰‡åˆ°æœ¬åœ°ï¼Œè¿”å›ç›¸å¯¹è·¯å¾„
    
    Args:
        cover_url: å°é¢å›¾ç‰‡URL
        book_id: ä¹¦ç±IDï¼ˆç”¨ä½œæ–‡ä»¶åï¼‰
        cover_dir: ä¿å­˜ç›®å½•
    
    Returns:
        str: ç›¸å¯¹è·¯å¾„ï¼Œä¾‹å¦‚ "covers/book_123.jpg"ï¼Œå¤±è´¥è¿”å› None
    """
    if not cover_url:
        return None

    try:
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(cover_dir, exist_ok=True)

        # ä»URLè·å–å›¾ç‰‡æ‰©å±•åï¼Œé»˜è®¤jpg
        ext = "jpg"
        try:
            # å°è¯•ä»URLè·¯å¾„è·å–æ‰©å±•å
            url_path = cover_url.split("?")[0]  # ç§»é™¤æŸ¥è¯¢å‚æ•°
            if "." in url_path:
                ext = url_path.split(".")[-1].lower()
                if ext not in ["jpg", "jpeg", "png", "gif", "webp"]:
                    ext = "jpg"
        except:
            pass

        # ä¿å­˜æ–‡ä»¶
        filename = f"book_{book_id}.{ext}"
        filepath = os.path.join(cover_dir, filename)

        response = requests.get(cover_url, timeout=10)
        response.raise_for_status()

        with open(filepath, "wb") as f:
            f.write(response.content)

        # è¿”å›ç›¸å¯¹è·¯å¾„ï¼ˆä½¿ç”¨æ­£æ–œæ å…¼å®¹ï¼‰
        relative_path = f"{cover_dir}/{filename}".replace("\\", "/")
        print(f"   ğŸ’¾ å·²ä¿å­˜: {relative_path}")
        return relative_path

    except Exception as e:
        print(f"   âš ï¸  å›¾ç‰‡ä¿å­˜å¤±è´¥: {str(e)}")
        return None


def process_backup(backup_file="klip-backup.json", output_file=None, cover_dir="covers"):
    """
    å¤„ç†å¤‡ä»½æ–‡ä»¶ï¼Œä¸ºæ¯æœ¬ä¹¦è·å–è±†ç“£å°é¢URLå’Œå›¾ç‰‡ï¼Œå¹¶å†™å›å¤‡ä»½æ–‡ä»¶
    
    Args:
        backup_file: è¾“å…¥çš„å¤‡ä»½æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºçš„å¤‡ä»½æ–‡ä»¶è·¯å¾„ï¼ˆé»˜è®¤åŒè¾“å…¥ï¼‰
        cover_dir: ä¿å­˜å°é¢å›¾ç‰‡çš„ç›®å½•
    """
    if output_file is None:
        output_file = backup_file

    # è¯»å–å¤‡ä»½æ–‡ä»¶
    print(f"ğŸ“– è¯»å–å¤‡ä»½æ–‡ä»¶: {backup_file}")
    with open(backup_file, "r", encoding="utf-8") as f:
        backup_data = json.load(f)

    books = backup_data.get("books", {})
    print(f"ğŸ“š æ‰¾åˆ° {len(books)} æœ¬ä¹¦")
    print(f"ğŸ“ å°é¢ä¿å­˜ç›®å½•: {cover_dir}")

    # ç»Ÿè®¡éœ€è¦æ›´æ–°çš„ä¹¦
    books_without_cover = [
        (bid, book) for bid, book in books.items()
        if not book.get("cover_url") or book.get("cover_url").strip() == ""
    ]
    print(f"ğŸ” éœ€è¦è·å–å°é¢çš„ä¹¦: {len(books_without_cover)} æœ¬")

    if not books_without_cover:
        print("âœ… æ‰€æœ‰ä¹¦ç±éƒ½å·²æœ‰å°é¢URLï¼Œæ— éœ€å¤„ç†")
        return

    # å¤„ç†æ¯æœ¬ä¹¦
    processed = 0
    failed = 0

    for idx, (book_id, book) in enumerate(books_without_cover, 1):
        book_title = book.get("book_title", "Unknown")
        author = book.get("author", "")

        print(f"\n[{idx}/{len(books_without_cover)}] å¤„ç†: {book_title} - {author}")

        try:
            result = search_and_fetch(book_title, author, save_image=False, headless=False)

            if result and result.get("cover_url"):
                cover_url = result["cover_url"]
                print(f"   ğŸ–¼ è·å–åˆ°URL: {cover_url[:50]}...")

                # ä¿å­˜å›¾ç‰‡å¹¶è·å–ç›¸å¯¹è·¯å¾„
                relative_path = save_cover_image(cover_url, book_id, cover_dir)

                if relative_path:
                    # ä¿å­˜ç›¸å¯¹è·¯å¾„è€Œä¸æ˜¯åŸå§‹URL
                    books[book_id]["cover_url"] = relative_path
                    print(f"   âœ… æˆåŠŸ")
                    processed += 1
                else:
                    print(f"   âš ï¸  å›¾ç‰‡ä¿å­˜å¤±è´¥")
                    failed += 1
            else:
                print(f"   âš ï¸  æœªè·å–åˆ°URL")
                break
                failed += 1

            # éšæœºç­‰å¾…ï¼Œé¿å…è¯·æ±‚è¿‡å¿«
            if idx < len(books_without_cover):
                sleep_time = random.uniform(3, 8)
                print(f"   â³ ç­‰å¾… {sleep_time:.1f}s...")
                time.sleep(sleep_time)

        except Exception as e:
            print(f"   âŒ é”™è¯¯: {str(e)}")
            failed += 1
            # å‡ºé”™åä¹Ÿè¦ç­‰å¾…
            if idx < len(books_without_cover):
                time.sleep(random.uniform(2, 5))

    # ä¿å­˜æ›´æ–°åçš„å¤‡ä»½æ–‡ä»¶
    print(f"\nğŸ’¾ ä¿å­˜å¤‡ä»½æ–‡ä»¶: {output_file}")
    with open(output_file, "w", encoding="utf-8") as f:
        json.dump(backup_data, f, ensure_ascii=False, indent=2)

    print(f"\nğŸ“Š å¤„ç†å®Œæˆ:")
    print(f"   âœ… æˆåŠŸ: {processed}")
    print(f"   âŒ å¤±è´¥: {failed}")
    print(f"   ğŸ“š æ€»è®¡: {len(books)}")
    print(f"   ğŸ“ å°é¢ä¿å­˜åœ¨: {os.path.abspath(cover_dir)}")


if __name__ == "__main__":
    backup_file = "klip-backup.json"

    # æ”¯æŒå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        backup_file = sys.argv[1]

    if not os.path.exists(backup_file):
        print(f"âŒ æ–‡ä»¶ä¸å­˜åœ¨: {backup_file}")
        sys.exit(1)

    try:
        process_backup(backup_file)
        print("\nâœ¨ æ‰€æœ‰æ“ä½œå®Œæˆï¼")
    except KeyboardInterrupt:
        print("\nâš ï¸  ç”¨æˆ·ä¸­æ–­")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ è‡´å‘½é”™è¯¯: {str(e)}")
        sys.exit(1)
